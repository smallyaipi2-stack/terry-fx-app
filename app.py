import streamlit as st
import requests
import pandas as pd
import yfinance as yf
import feedparser
import urllib.parse
from datetime import datetime, timedelta

# 1. ç¶²é åŸºæœ¬è¨­å®šèˆ‡æ¨™é¡Œè®Šæ›´
st.set_page_config(page_title="Terryæˆ°æƒ…å®¤", page_icon="ğŸ“ˆ", layout="wide")

# CSS æ¨£å¼ä¿®æ­£ï¼šç§»é™¤å¼·åˆ¶èƒŒæ™¯è‰²ï¼Œè®“ç³»çµ±è‡ªå‹•é©æ‡‰æ·±æ·ºæ¨¡å¼
st.markdown("""
    <style>
    /* è®“æŒ‡æ¨™å¡ç‰‡è‡ªå‹•é©æ‡‰æ·±æ·ºä¸»é¡Œè‰² */
    .stMetric {
        background-color: var(--secondary-background-color);
        padding: 10px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border: 1px solid var(--border-color);
    }
    /* æˆ°ç•¥æŒ‡æ¨™å¡ç‰‡çµ±ä¸€é¢¨æ ¼ */
    .status-box, .comparison-box {
        padding: 12px;
        border-radius: 8px;
        background-color: var(--secondary-background-color); /* è‡ªå‹•é©æ‡‰ */
        border: 1px solid var(--border-color);
        margin-bottom: 10px;
    }
    .status-box b { color: var(--text-color); }
    .time-label { font-size: 12px; color: gray; margin-bottom: 2px; }
    </style>
    """, unsafe_allow_html=True)

# 2. è³‡æ–™æŠ“å–é‚è¼¯
@st.cache_data(ttl=600)
def fetch_all_data():
    rates = {'å°å¹£ (TWD)': 1.0}
    try:
        r = requests.get("https://rate.bot.com.tw/xrt/flcsv/0/day", timeout=10)
        r.encoding = 'utf-8-sig'
        for line in r.text.split('\n'):
            parts = line.split(',')
            if len(parts) < 13: continue
            code = parts[0].strip()
            target_map = {'USD': 'ç¾é‡‘ (USD)', 'JPY': 'æ—¥åœ“ (JPY)', 'EUR': 'æ­å…ƒ (EUR)', 'KRW': 'éŸ“å…ƒ (KRW)', 'MYR': 'é¦¬å¹£ (MYR)', 'THB': 'æ³°éŠ– (THB)', 'SGD': 'æ–°å¹£ (SGD)'}
            for k, v in target_map.items():
                if k in code: rates[v] = float(parts[12].strip())
    except: pass

    stocks = {}
    stock_targets = {'1216.TW': 'çµ±ä¸€', '1201.TW': 'å‘³å…¨', '1210.TW': 'å¤§æˆ', '1231.TW': 'è¯è¯é£Ÿ', '1227.TW': 'ä½³æ ¼', '1707.TW': 'è‘¡è„ç‹', '2912.TW': 'çµ±ä¸€è¶…', '5903.TWO': 'å…¨å®¶'}
    try:
        for symbol, name in stock_targets.items():
            ticker = yf.Ticker(symbol)
            info = ticker.history(period='2d')
            if len(info) >= 2:
                p, c = info['Close'].iloc[-1], info['Close'].iloc[-1] - info['Close'].iloc[-2]
                stocks[name] = (p, c)
    except: pass

    news = []
    try:
        query = "site:foodnext.net OR site:money.udn.com OR site:bnext.com.tw"
        feed = feedparser.parse(f"https://news.google.com/rss/search?q={urllib.parse.quote(query)}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant")
        news = feed.entries[:7]
    except: pass

    return rates, stocks, news

rates_dict, stocks_dict, news_list = fetch_all_data()

# 3. ä»‹é¢å‘ˆç¾
st.title("ğŸ“ˆ Terryæˆ°æƒ…å®¤") # æ¨™é¡Œå·²ä¿®æ”¹
st.write(f"åŸ·è¡Œé•·æ‚¨å¥½ï¼Œè³‡æ–™åŒæ­¥æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

col_main, col_right = st.columns([3, 1])

with col_main:
    st.subheader("ğŸ“Š å³æ™‚åŒ¯ç‡ (å°å°å¹£)")
    if rates_dict and len(rates_dict) > 1:
        items = [i for i in rates_dict.items() if i[0] != 'å°å¹£ (T
