import streamlit as st
import requests
import pandas as pd
import yfinance as yf
import feedparser
import urllib.parse
from datetime import datetime

# 1. ç¶²é åŸºæœ¬è¨­å®š
st.set_page_config(page_title="Terryçš„æ›åŒ¯å°å·¥å…·", page_icon="ğŸ“ˆ", layout="wide")

# CSS æ¨£å¼ä¿®æ­£
st.markdown("""
    <style>
    .stMetric {
        background-color: var(--secondary-background-color);
        padding: 10px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border: 1px solid var(--border-color);
    }
    </style>
    """, unsafe_allow_html=True)

# 2. è³‡æ–™æŠ“å–é‚è¼¯
@st.cache_data(ttl=600)
def fetch_all_data():
    rates = {'å°å¹£ (TWD)': 1.0}
    try:
        r = requests.get("https://rate.bot.com.tw/xrt/flcsv/0/day", timeout=10)
        r.encoding = 'utf-8-sig'
        for line in r.text.split('\n'):
            parts = line.split(',')
            if len(parts) < 13: continue
            code = parts[0].strip()
            # æ”¯æ´å¹£åˆ¥
            target_map = {'USD': 'ç¾é‡‘ (USD)', 'JPY': 'æ—¥åœ“ (JPY)', 'EUR': 'æ­å…ƒ (EUR)', 'KRW': 'éŸ“å…ƒ (KRW)', 'MYR': 'é¦¬å¹£ (MYR)', 'THB': 'æ³°éŠ– (THB)', 'SGD': 'æ–°å¹£ (SGD)'}
            for k, v in target_map.items():
                if k in code: rates[v] = float(parts[12].strip())
    except: pass

    stocks = {}
    # ç”¢æ¥­æ¨™ç«¿ç›£æ§åå–®ï¼ŒåŒ…å«åŸ·è¡Œé•·æŒ‡å®šçš„ä½³æ ¼èˆ‡è‘¡è„ç‹
    stock_targets = {
        '1216.TW': 'çµ±ä¸€', '1201.TW': 'å‘³å…¨', '1210.TW': 'å¤§æˆ', 
        '1231.TW': 'è¯è¯é£Ÿ', '1227.TW': 'ä½³æ ¼', '1707.TW': 'è‘¡è„ç‹', 
        '2912.TW': 'çµ±ä¸€è¶…', '5903.TWO': 'å…¨å®¶'
    }
    try:
        for symbol, name in stock_targets.items():
            ticker = yf.Ticker(symbol)
            info = ticker.history(period='2d')
            if len(info) >= 2:
                p, prev = info['Close'].iloc[-1], info['Close'].iloc[-2]
                stocks[name] = (p, p - prev)
    except: pass

    news = []
    try:
        # é–å®šé£ŸåŠ›ã€ç¶“æ¿Ÿæ—¥å ±ã€æ•¸ä½æ™‚ä»£
        query = "site:foodnext.net OR site:money.udn.com OR site:bnext.com.tw"
        feed = feedparser.parse(f"https://news.google.com/rss/search?q={urllib.parse.quote(query)}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant")
        news = feed.entries[:7]
    except: pass

    return rates, stocks, news

rates_dict, stocks_dict, news_list = fetch_all_data()

# 3. ä»‹é¢å‘ˆç¾
st.title("ğŸ“ˆ Terryçš„æ›åŒ¯å°å·¥å…· (æµ·å¤–æˆ°æƒ…å®¤ç‰ˆ)")
st.write(f"åŸ·è¡Œé•·æ‚¨å¥½ï¼Œä»Šæ—¥ç³»çµ±æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

col_main, col_news = st.columns([3, 1])

with col_main:
    # ç¬¬ä¸€å±¤ï¼šå³æ™‚åŒ¯ç‡ (å°å°å¹£)
    st.subheader("ğŸ“Š å³æ™‚åŒ¯ç‡ (å°å°å¹£)")
    if rates_dict and len(rates_dict) > 1:
        items = [i for i in rates_dict.items() if i[0] != 'å°å¹£ (TWD)']
        cols = st.columns(len(items))
        for i, (name, rate) in enumerate(items):
            cols[i].metric(name, f"{rate:.4f}")
    
    st.divider()

    # ç¬¬äºŒå±¤ï¼šæ›åŒ¯è·Ÿæ­·å²è¶¨å‹¢ (æ’åºæå‰)
    c1, c2 = st.columns([1, 1.2])
    with c1:
        st.subheader("ğŸ”„ å¿«é€Ÿæ›ç®—")
        amt = st.number_input("é‡‘é¡", min_value=0.0, value=100.0, key="calc_amt")
        f_c = st.selectbox("å¾", list(rates_dict.keys()), index=1, key="f_c")
        t_c = st.selectbox("åˆ°", list(rates_dict.keys()), index=0, key="t_c")
        if st.button("è¨ˆç®—çµæœ", use_container_width=True):
            res = (amt * rates_dict[f_c]) / rates_dict[t_c]
            st.success(f"### {res:,.2f} {t_c}")
    
    with c2:
        st.subheader("ğŸ“ˆ æ­·å²è¶¨å‹¢")
        target = st.selectbox("è¶¨å‹¢å¹£åˆ¥", [n for n in rates_dict.keys() if n != 'å°å¹£ (TWD)'], key="trend_c")
        range_p = st.radio("ç¯„åœ", ["1mo", "3mo", "6mo", "1y"], horizontal=True, key="range_p")
        s_map = {'ç¾é‡‘ (USD)': 'USDTWD=X', 'æ—¥åœ“ (JPY)': 'JPYTWD=X', 'æ­å…ƒ (EUR)': 'EURTWD=X', 'éŸ“å…ƒ (KRW)': 'KRWTWD=X', '
